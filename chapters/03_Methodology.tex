% %!TEX root = ../main.tex
\chapter{Methodology}
\label{chp:methodology}

In this chapter, we provide a formal definition of the problem of joint entity and relation extraction in section \hyperref[sec:probdef]{[3.1]}. Then, in section \hyperref[sec:approach]{[3.2]}, we describe our approach in detail. First explaining the entity model in section \hyperref[sec:entitymodel]{[3.2.1]}, and then describing the relation model in section \hyperref[sec:relationmodel]{[3.2.2]}.
\section{Problem Definition}
\label{sec:probdef}
Given \(X\) an input sentence consisting of \(n\) tokens \(x_1,x_2,...,x_n\). Let \(S = {s_1, s_2,...,s_m}\) be all the possible spans in \(X\) of up to length \(L\) and \(START(i)\) and \(END(i)\) denote start and end indices of \(s_i\). The problem can be decomposed into two sub-tasks:

\textbf{Named entity recognition} Let \(E\) denote a set of pre-defined entity types. The named entity recognition task is, for each span \(s_i \in S\), to predict an entity type \[y_e(s_i) \in E\] or, span \(s_i\) is not an entity: \[y_e(s_i) =\epsilon\]

The output of the task is \[Y_e = {(s_i , e) : s_i \in S, e \in E}\].


\textbf{Relation extraction} Let \(R\) denote a set of predefined relation types. The task is, for every pair of spans \(si \in S\), \(sj \in S\), to predict a relation type \[y_r(s_i , s_j ) \in R\], or there is no relation between them: \[y_r(s_i , s_j ) =\epsilon\]. The output of the task is \[Y_r = {(s_i , s_j , r) : s_i , s_j \in S, r \in R}\].

\section{Our Approach}
\label{sec:approach}

We based our approach on the state of the art proposed by Zhong et al. \cite{Zhong2020AFE}. The simplicity of their model and its performance make it a prime candidate for NER and RE on new datasets. Therefore we first reproduced their results on the SciERC dataset. Then, we prove that their model can be generalized to other datasets. In the next chapter, we will dive deeper into our experiments and demonstrate how we trained and evaluated their model on new NER and RE datasets. Namely the NYT \hyperref[sec:nytdataset]{[2.2.3.1]} and TACRED\hyperref[sec:tacreddataset]{[2.2.3.2]} datasets. The goal is to have a framework that, given any NER and RE dataset, can be easily used to train NER and RE models.\\

\subsection{Entity model}
\label{sec:entitymodel}
The entity model is inspired by previous research (Lee et al. \cite{lee-etal-2017-end}; Luan et al. \cite{luan-etal-2019-general}; Wadden et al. \cite{Wadden2019EntityRA}). It begins by using a pre-trained language model, such as BERT, to understand the context of each word in a sentence. For any given segment of text, known as a 'span', we create a context representation \(\text{x}_t\) for each input token \(x_t\). This is done by combining the context of the span's first and last words with additional features that capture the span's length. We then use this combined information to calculate the likelihood of each possible entity type that this span could represent.\\
Formally, Let \(S\) be an input sentence, and \(s_i\) a span of \(S\)  \(s_i \in S\), we can define the span representation \(h_e(s_i)\) as\cite{Zhong2020AFE}: \[h_e(s_i) = [x_{START(i)} ; x_{END(i)} ; \phi(s_i)]\], where \(\phi(s_i) \in R^d_F\) is a representation of the span width features. Finally, \(h_e(s_i)\) becomes the input to a \ac{FFN} that will predict the entity type. Or, more precisely, its probability distribution: \[e \in E \cup {\epsilon}: P_e(e | s_i)\].

\subsection{Relation Model}
\label{sec:relationmodel}
The relation model function is to take two spans \(s_i\) , \(s_j\), which are the 'subject' and 'object' as input and output a relation between them. Or output \(\epsilon\) if there's no relation. Most works we examined (Luan et al. \cite{luan-etal-2019-general}; Wadden et al. \cite{Wadden2019EntityRA}) use the same span representations \(h_e(s_i)\), \(h_e(s_j)\) in the relation model to predict the relation between \(s_i\) and \(s_j\) . Hover, Zhong et al. \cite{Zhong2020AFE} suggest that while these representations can understand the context surrounding each entity independently, they might not effectively identify the connections or relationships between pairs of text segments. They also point out that using the same contextual information for different pairs of text segments might not always be the best approach. For example, the phrase "is a" is important for recognizing the relationship between MORPA and PARSER in Figure 1, but does not help in understanding the connection between MORPA and TEXT-TO-SPEECH.

\begin{figure}[ht]
    \centering
    \includegraphics[width=1\textwidth]{figures/figure1.png}
    \caption{An input sentence from the SciERC dataset. Luan et al. \cite{luan-etal-2019-general}}
    \label{fig:examplefromsciercdataset}
\end{figure}

Instead, Zhong et al. \cite{Zhong2020AFE} propose a relation model that looks at each pair of spans separately and adds specific markers in the initial processing stage. These markers indicate which span is the subject and which is the object, as well as their types, to improve the model's understanding. Formally, Let \(X\) be an input sentence and \(s_i\) , \(s_j\) be a pair of subject-object spans and \(ei , ej \in E \cup {\epsilon}\) are their types respectively. Then we define text markers as \(\langle S:e_i\rangle\), \(\langle /S:e_i\rangle\), \(\langle O:e_j\rangle\), and \(\langle /O:e_j\rangle\), and embedded them into \(X\) before and after \(s_i\) and \(s_j\) (Figure 1 (b)). Let \(\widehat{X}\) be the new sequence after inserting the markers: \[\widehat{X} = ...\langle S:e_i\rangle,x_{START(i)},...,x_{END(i)},\langle /S:e_i\rangle\,...\langle /O:e_j\rangle,x_{START(j)},...,x_{END(j)}\langle /O:e_j\rangle\]

Next, we use another pre-trained encoder on \(\widehat{X}\) and we refer to its output representations with by \(\widehat{x}_t\). We combine the outputs from their starting points to understand the relationship between the two spans. This gives us a combined representation: \[h_r(s_i,s_j)=[{\widehat{x}}_{\widehat{START(i)}};{\widehat{x}}_{\widehat{START(j)}}]\]
where \(\widehat{START(i)}\) and \(\widehat{START(j)}\) are the indices of \(\langle S:e_i\rangle\) and \(\langle O:e_j\rangle\) in \(\widehat{X}\). Finally, \(h_r(s_i,s_j)\) will be the input to an FFN that will predict the relation between \(s_i\) and \(s_j\): \[r \in R \cup {\epsilon}: P_r(r|s_i , s_j )\].

The approach of using special markers to identify subjects and objects in a text is not particularly novel and has been explored before in classification studies (Zhang et al.\cite{zhang-etal-2019-ernie}; Soares et al.\cite{baldini-soares-etal-2019-matching}; Peters et al.\cite{peters2019knowledge}). However, these studies usually focus on classifying the relationship between one pair of subjects and objects within a sentence Zhang et al.\cite{zhang-etal-2017-position}, such as in the TACRED dataset\hyperref[sec:tacreddataset]{[2.2.3.2]}. The effectiveness of this method has not been fully tested in the end-to-end setting like the Zhong et al. \cite{Zhong2020AFE} hope to classify the relations amongst more entity mentions. They saw a significant improvement in their solution, strengthening the idea that different context-aware representations are invaluable for understanding the relations between entities pairs in one example.. Furthermore, Zhang et al.\cite{zhang-etal-2019-ernie}; Soares et al.\cite{baldini-soares-etal-2019-matching} used untyped only markers (e.g., \(\langle S:\rangle\), \(\langle /S:\rangle\)) and previous end-to-end models (e.g., (Wadden et al.\cite{Wadden2019EntityRA})) only inject the entity type information into the relation model through auxiliary losses. Zhong et al. \cite{Zhong2020AFE} found that injecting type information at the input layer is very helpful in distinguishing entity types — for example, whether “Disney” refers to a person or an organization— before trying to understand the relations.